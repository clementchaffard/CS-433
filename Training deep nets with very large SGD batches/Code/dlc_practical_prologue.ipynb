{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "######################################################################\n",
    "\n",
    "parser = argparse.ArgumentParser(description='DLC prologue file for practical sessions.')\n",
    "\n",
    "parser.add_argument('--full',\n",
    "                    action='store_true', default=False,\n",
    "                    help = 'Use the full set, can take ages (default False)')\n",
    "\n",
    "parser.add_argument('--tiny',\n",
    "                    action='store_true', default=False,\n",
    "                    help = 'Use a very small set for quick checks (default False)')\n",
    "\n",
    "parser.add_argument('--seed',\n",
    "                    type = int, default = 0,\n",
    "                    help = 'Random seed (default 0, < 0 is no seeding)')\n",
    "\n",
    "parser.add_argument('--cifar',\n",
    "                    action='store_true', default=False,\n",
    "                    help = 'Use the CIFAR data-set and not MNIST (default False)')\n",
    "\n",
    "parser.add_argument('--data_dir',\n",
    "                    type = str, default = None,\n",
    "                    help = 'Where are the PyTorch data located (default $PYTORCH_DATA_DIR or \\'./data\\')')\n",
    "\n",
    "# Timur's fix\n",
    "parser.add_argument('-f', '--file',\n",
    "                    help = 'quick hack for jupyter')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.seed >= 0:\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "######################################################################\n",
    "# The data\n",
    "\n",
    "def convert_to_one_hot_labels(input, target):\n",
    "    tmp = input.new_zeros(target.size(0), target.max() + 1)\n",
    "    tmp.scatter_(1, target.view(-1, 1), 1.0)\n",
    "    return tmp\n",
    "\n",
    "def load_data(cifar = None, one_hot_labels = False, normalize = False, flatten = True):\n",
    "\n",
    "    if args.data_dir is not None:\n",
    "        data_dir = args.data_dir\n",
    "    else:\n",
    "        data_dir = os.environ.get('PYTORCH_DATA_DIR')\n",
    "        if data_dir is None:\n",
    "            data_dir = './data'\n",
    "\n",
    "    if args.cifar or (cifar is not None and cifar):\n",
    "        print('* Using CIFAR')\n",
    "        cifar_train_set = datasets.CIFAR10(data_dir + '/cifar10/', train = True, download = True)\n",
    "        cifar_test_set = datasets.CIFAR10(data_dir + '/cifar10/', train = False, download = True)\n",
    "\n",
    "        train_input = torch.from_numpy(cifar_train_set.data)\n",
    "        train_input = train_input.transpose(3, 1).transpose(2, 3).float()\n",
    "        train_target = torch.tensor(cifar_train_set.targets, dtype = torch.int64)\n",
    "\n",
    "        test_input = torch.from_numpy(cifar_test_set.data).float()\n",
    "        test_input = test_input.transpose(3, 1).transpose(2, 3).float()\n",
    "        test_target = torch.tensor(cifar_test_set.targets, dtype = torch.int64)\n",
    "\n",
    "    else:\n",
    "        print('* Using MNIST')\n",
    "        mnist_train_set = datasets.MNIST(data_dir + '/mnist/', train = True, download = True)\n",
    "        mnist_test_set = datasets.MNIST(data_dir + '/mnist/', train = False, download = True)\n",
    "\n",
    "        train_input = mnist_train_set.data.view(-1, 1, 28, 28).float()\n",
    "        train_target = mnist_train_set.targets\n",
    "        test_input = mnist_test_set.data.view(-1, 1, 28, 28).float()\n",
    "        test_target = mnist_test_set.targets\n",
    "\n",
    "    if flatten:\n",
    "        train_input = train_input.clone().reshape(train_input.size(0), -1)\n",
    "        test_input = test_input.clone().reshape(test_input.size(0), -1)\n",
    "\n",
    "    if args.full:\n",
    "        if args.tiny:\n",
    "            raise ValueError('Cannot have both --full and --tiny')\n",
    "    else:\n",
    "        if args.tiny:\n",
    "            print('** Reduce the data-set to the tiny setup')\n",
    "            train_input = train_input.narrow(0, 0, 500)\n",
    "            train_target = train_target.narrow(0, 0, 500)\n",
    "            test_input = test_input.narrow(0, 0, 100)\n",
    "            test_target = test_target.narrow(0, 0, 100)\n",
    "        else:\n",
    "            print('** Reduce the data-set (use --full for the full thing)')\n",
    "            train_input = train_input.narrow(0, 0, 1000)\n",
    "            train_target = train_target.narrow(0, 0, 1000)\n",
    "            test_input = test_input.narrow(0, 0, 1000)\n",
    "            test_target = test_target.narrow(0, 0, 1000)\n",
    "\n",
    "    print('** Use {:d} train and {:d} test samples'.format(train_input.size(0), test_input.size(0)))\n",
    "\n",
    "    if one_hot_labels:\n",
    "        train_target = convert_to_one_hot_labels(train_input, train_target)\n",
    "        test_target = convert_to_one_hot_labels(test_input, test_target)\n",
    "\n",
    "    if normalize:\n",
    "        mu, std = train_input.mean(), train_input.std()\n",
    "        train_input.sub_(mu).div_(std)\n",
    "        test_input.sub_(mu).div_(std)\n",
    "\n",
    "    return train_input, train_target, test_input, test_target\n",
    "\n",
    "######################################################################\n",
    "\n",
    "def mnist_to_pairs(nb, input, target):\n",
    "    input = torch.functional.F.avg_pool2d(input, kernel_size = 2)\n",
    "    a = torch.randperm(input.size(0))\n",
    "    a = a[:2 * nb].view(nb, 2)\n",
    "    input = torch.cat((input[a[:, 0]], input[a[:, 1]]), 1)\n",
    "    classes = target[a]\n",
    "    target = (classes[:, 0] <= classes[:, 1]).long()\n",
    "    return input, target, classes\n",
    "\n",
    "######################################################################\n",
    "\n",
    "def generate_pair_sets(nb):\n",
    "    if args.data_dir is not None:\n",
    "        data_dir = args.data_dir\n",
    "    else:\n",
    "        data_dir = os.environ.get('PYTORCH_DATA_DIR')\n",
    "        if data_dir is None:\n",
    "            data_dir = './data'\n",
    "\n",
    "    train_set = datasets.MNIST(data_dir + '/mnist/', train = True, download = True)\n",
    "    train_input = train_set.data.view(-1, 1, 28, 28).float()\n",
    "    train_target = train_set.targets\n",
    "\n",
    "    test_set = datasets.MNIST(data_dir + '/mnist/', train = False, download = True)\n",
    "    test_input = test_set.data.view(-1, 1, 28, 28).float()\n",
    "    test_target = test_set.targets\n",
    "\n",
    "    return mnist_to_pairs(nb, train_input, train_target) + \\\n",
    "           mnist_to_pairs(nb, test_input, test_target)\n",
    "\n",
    "######################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
